{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\sibonelo.malakiya\\anaconda3\\lib\\site-packages (2.3.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\sibonelo.malakiya\\anaconda3\\lib\\site-packages (from lightgbm) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sibonelo.malakiya\\anaconda3\\lib\\site-packages (from lightgbm) (0.23.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\sibonelo.malakiya\\anaconda3\\lib\\site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sibonelo.malakiya\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\sibonelo.malakiya\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from math import sqrt\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/SiboneloJunior/To-Vaccinate-or-Not-to-Vaccinate-It-s-not-a-Question/master/Dataset/Train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/SiboneloJunior/To-Vaccinate-or-Not-to-Vaccinate-It-s-not-a-Question/master/Dataset/Test.csv')\n",
    "sample = pd.read_csv('https://raw.githubusercontent.com/SiboneloJunior/To-Vaccinate-or-Not-to-Vaccinate-It-s-not-a-Question/master/Dataset/SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10001, 4)\n",
      "(5177, 2)\n",
      "(5177, 2)\n"
     ]
    }
   ],
   "source": [
    "# Shape\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>safe_text</th>\n",
       "      <th>label</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CL1KWCMY</td>\n",
       "      <td>Me &amp;amp; The Big Homie meanboy3000 #MEANBOY #M...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E3303EME</td>\n",
       "      <td>I'm 100% thinking of devoting my career to pro...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M4IVFSMS</td>\n",
       "      <td>#whatcausesautism VACCINES, DO NOT VACCINATE Y...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1DR6ROZ4</td>\n",
       "      <td>I mean if they immunize my kid with something ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J77ENIIE</td>\n",
       "      <td>Thanks to &lt;user&gt; Catch me performing at La Nui...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                          safe_text  label  \\\n",
       "0  CL1KWCMY  Me &amp; The Big Homie meanboy3000 #MEANBOY #M...    0.0   \n",
       "1  E3303EME  I'm 100% thinking of devoting my career to pro...    1.0   \n",
       "2  M4IVFSMS  #whatcausesautism VACCINES, DO NOT VACCINATE Y...   -1.0   \n",
       "3  1DR6ROZ4  I mean if they immunize my kid with something ...   -1.0   \n",
       "4  J77ENIIE  Thanks to <user> Catch me performing at La Nui...    0.0   \n",
       "\n",
       "   agreement  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        1.0  \n",
       "4        1.0  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>safe_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00BHHHP1</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; ... &amp;amp; 4 a vaccine given 2 he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00UNMD0E</td>\n",
       "      <td>Students starting school without whooping coug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01AXPTJF</td>\n",
       "      <td>I'm kinda over every ep of &lt;user&gt; being \"rippe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01HOEQJW</td>\n",
       "      <td>How many innocent children die for lack of vac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01JUKMAO</td>\n",
       "      <td>CDC eyeing bird flu vaccine for humans, though...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                          safe_text\n",
       "0  00BHHHP1  <user> <user> ... &amp; 4 a vaccine given 2 he...\n",
       "1  00UNMD0E  Students starting school without whooping coug...\n",
       "2  01AXPTJF  I'm kinda over every ep of <user> being \"rippe...\n",
       "3  01HOEQJW  How many innocent children die for lack of vac...\n",
       "4  01JUKMAO  CDC eyeing bird flu vaccine for humans, though..."
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00BHHHP1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00UNMD0E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01AXPTJF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01HOEQJW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01JUKMAO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  label\n",
       "0  00BHHHP1      0\n",
       "1  00UNMD0E      0\n",
       "2  01AXPTJF      0\n",
       "3  01HOEQJW      0\n",
       "4  01JUKMAO      0"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id     0\n",
       "safe_text    0\n",
       "label        0\n",
       "agreement    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove nulls\n",
    "\n",
    "train = train.dropna()\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the null on the test dataset witha random string\n",
    "\n",
    "test = test.fillna('CDC eyeing bird flu vaccine for humans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "\n",
    "train = train.drop(['tweet_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rows with reasonable agreement\n",
    "\n",
    "train = train[train['agreement'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels into integers\n",
    "\n",
    "label_int = train['label'].astype(int)\n",
    "train['label'] = label_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated tweets\n",
    "\n",
    "train = train.drop_duplicates(subset='safe_text', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Lemmetizer class\n",
    "\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define Punctuations + User string\n",
    "\n",
    "punctuation = list(string.punctuation)\n",
    "\n",
    "sw_pun = punctuation + ['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning function_1\n",
    "\n",
    "def preprocess(tweet):\n",
    "    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\",\n",
    "                   \"\", tweet)                       # removing urls\n",
    "    tweet = re.sub('[^\\w]',' ',tweet)               # remove embedded special characters        \n",
    "    tweet = re.sub('[\\d]','',tweet)                 # this will remove numeric characters\n",
    "    tweet = tweet.lower()\n",
    "    words = tweet.split()  \n",
    "    sentence = \"\"\n",
    "    for word in words:     \n",
    "        if word not in (sw_pun):                    # removing punctuations + 'User'                \n",
    "            word = lemma.lemmatize(word,pos = 'v')  # converting to lemma    \n",
    "            if len(word) > 3:                       # we will consider words with length > 3\n",
    "                sentence = sentence + word + ' '             \n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function_1 to train and test datasets\n",
    "\n",
    "train['safe_text'] = train['safe_text'].apply(lambda s : preprocess(s))\n",
    "test['safe_text'] = test['safe_text'].apply(lambda s : preprocess(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning function_2 - emojis\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function_1 to train and test datasets\n",
    "\n",
    "train['safe_text'] = train['safe_text'].apply(lambda s : remove_emoji(s))\n",
    "test ['safe_text'] = test ['safe_text'].apply(lambda s : remove_emoji(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering function\n",
    "\n",
    "def add_features(df) :\n",
    "    \n",
    "    punctuation=string.punctuation\n",
    "    stop = stopwords.words('english')\n",
    "    \n",
    "    df['safe_text']=df['safe_text'].astype('category')\n",
    "    df['word_count']=df['safe_text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "    df['char_count'] = df['safe_text'].str.len()\n",
    "\n",
    "    df['stopwords'] = df['safe_text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "    df['word_density'] = df['char_count'] / (df['word_count']+1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to both train and test\n",
    "\n",
    "train = add_features(train)\n",
    "test  = add_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "\n",
    "col=['word_count', 'char_count',\n",
    " 'stopwords', 'word_density']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training + testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "v_name = TfidfVectorizer(ngram_range=(1,1),stop_words=\"english\", analyzer='word')\n",
    "name_tr =v_name.fit_transform(train['safe_text'])\n",
    "name_ts =v_name.transform(test['safe_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse\n",
    "\n",
    "features_train = sparse.hstack((train[col],name_tr )).tocsr()\n",
    "features_test = sparse.hstack((test[col],name_ts )).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= features_train\n",
    "y= train['label']\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(X, y, stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4877422070897596\n",
      "0.5543156389774229\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lg = LGBMRegressor(random_state=42,learning_rate=0.05)\n",
    "\n",
    "lg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = lg.predict(X_val)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_train.values,lg.predict(X_train))))\n",
    "print(np.sqrt(mean_squared_error(y_val.values,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_test\n",
    "\n",
    "y_sub = lg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['label'] = y_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00BHHHP1</td>\n",
       "      <td>0.252449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00UNMD0E</td>\n",
       "      <td>0.612813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01AXPTJF</td>\n",
       "      <td>0.112282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01HOEQJW</td>\n",
       "      <td>0.507697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01JUKMAO</td>\n",
       "      <td>0.323991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5172</th>\n",
       "      <td>ZXVVNC5O</td>\n",
       "      <td>0.912599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5173</th>\n",
       "      <td>ZYIANVI8</td>\n",
       "      <td>0.077235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5174</th>\n",
       "      <td>ZYITEHAH</td>\n",
       "      <td>0.446669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5175</th>\n",
       "      <td>ZZ3BMBTG</td>\n",
       "      <td>0.781136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5176</th>\n",
       "      <td>ZZIYCVNH</td>\n",
       "      <td>0.222239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5177 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id     label\n",
       "0     00BHHHP1  0.252449\n",
       "1     00UNMD0E  0.612813\n",
       "2     01AXPTJF  0.112282\n",
       "3     01HOEQJW  0.507697\n",
       "4     01JUKMAO  0.323991\n",
       "...        ...       ...\n",
       "5172  ZXVVNC5O  0.912599\n",
       "5173  ZYIANVI8  0.077235\n",
       "5174  ZYITEHAH  0.446669\n",
       "5175  ZZ3BMBTG  0.781136\n",
       "5176  ZZIYCVNH  0.222239\n",
       "\n",
       "[5177 rows x 2 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('model_v9.csv' , index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zindi Leaderboard score = 0.5867"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
